{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Mean_Shift_Clustering.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JGZZQXtQxq_E",
        "PeOIbNvIxpCi"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Koz3muRlphF8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Deep Mean Shift Clustering"
      ]
    },
    {
      "metadata": {
        "id": "JKufrmf7pnTD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reqs"
      ]
    },
    {
      "metadata": {
        "id": "StuNlkIe05Z9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download"
      ]
    },
    {
      "metadata": {
        "id": "oV9skoUQZKlz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "!pip install pillow==4.1.1\n",
        "# %reload_ext autoreload\n",
        "# %autoreload\n",
        "!pip install python-mnist\n",
        "# !/usr/local/bin/python -m pip install visdom\n",
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# !unzip ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1lTjIOhb09zD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import"
      ]
    },
    {
      "metadata": {
        "id": "iKrYZe-LH0MI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import mnist\n",
        "# import visdom\n",
        "# vis = visdom.Visdom(port='6006')\n",
        "import pickle\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable, Function, gradcheck"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2eNoyMkTTyQT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ]
    },
    {
      "metadata": {
        "id": "ib4AP5jVT4H5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download"
      ]
    },
    {
      "metadata": {
        "id": "PhNI3-5v2H9f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
        "root = '/content'\n",
        "train = torchvision.datasets.MNIST(root, train=True, transform=trans, target_transform=None, download=True)\n",
        "root = '/content'\n",
        "test = torchvision.datasets.MNIST(root, train=False, transform=trans, target_transform=None, download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gkPpTpiYT7YN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load"
      ]
    },
    {
      "metadata": {
        "id": "tbwnZznP5iFx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_batch_size = 256\n",
        "test_batch_size = 100\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "                 dataset=train,\n",
        "                 batch_size=train_batch_size,\n",
        "                 shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "                dataset=test,\n",
        "                batch_size=test_batch_size,\n",
        "                shuffle=False)\n",
        "\n",
        "print ('total trainning batch number: '+ str(len(train_loader)))\n",
        "print ('total testing batch number: '+ str(len(test_loader)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bG7TTpwZ0eDE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# AE Def"
      ]
    },
    {
      "metadata": {
        "id": "5Rv6dc5ncryb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plotter"
      ]
    },
    {
      "metadata": {
        "id": "naEf0qzWctVk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_regen(model):\n",
        "  im_data = mnist.MNIST('/content/raw/')\n",
        "\n",
        "  train_image, train_label = im_data.load_training()\n",
        "\n",
        "  train_image = np.array(train_image)\n",
        "\n",
        "  train_label = np.array(train_label)\n",
        "\n",
        "  train_image = train_image.reshape(-1, 28, 28, 1)\n",
        "\n",
        "  fig=plt.figure(figsize=(10,40))\n",
        "\n",
        "  # print(train_image[0].shape)\n",
        "  num_im = 4\n",
        "  for i in range(num_im):\n",
        "    data = np.array(train_image[i], dtype='float')\n",
        "    data = data.reshape((28, 28))\n",
        "    fig.add_subplot(1, num_im, i+1)\n",
        "    plt.imshow(data, cmap='gray')\n",
        "  plt.show()\n",
        "\n",
        "  fig=plt.figure(figsize=(10,40))\n",
        "\n",
        "  # print(train_image[0].shape)\n",
        "  num_im = 4\n",
        "  for i in range(num_im):\n",
        "\n",
        "    data = np.array(train_image[i], dtype='float')\n",
        "    data = data.reshape((28, 28, 1))\n",
        "    data = np.transpose(data)\n",
        "    data = data.reshape((1, 1, 28, 28))\n",
        "\n",
        "    data = torch.from_numpy(data)\n",
        "    data = (data.float() - 0.5) / 1.0\n",
        "    out, embed = model(data.cuda())\n",
        "#     out = model(data.cuda())\n",
        "    out = out.cpu().detach()\n",
        "    out = out.reshape((28, 28))\n",
        "    out = np.array(out, dtype='float')\n",
        "    out = (out * 1.0) + 0.5\n",
        "    out = (out - np.min(out)) * 255 / (np.max(out) - np.min(out))\n",
        "#     up = np.where(out >= 128)\n",
        "#     down = np.where(out < 128)\n",
        "#     out[up] = 1.\n",
        "#     out[down] = 0.\n",
        "    fig.add_subplot(1, num_im, i+1)\n",
        "    plt.imshow(out.T, cmap='gray')\n",
        "  plt.show()\n",
        "\n",
        "# plot_regen(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gTOeiQQMt_Yq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Mean Shift Cluster"
      ]
    },
    {
      "metadata": {
        "id": "L3dCZ_O_uDQy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Mean_Shift_Cluster(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, delta, eta, ms_iter):\n",
        "    super(Mean_Shift_Cluster, self).__init__()\n",
        "    self.delta = delta\n",
        "    self.eta = eta\n",
        "    self.ms_iter = ms_iter\n",
        "\n",
        "  def mean_shift_once(self, X):\n",
        "    S = torch.mm(X.t(), X)\n",
        "    K = torch.exp(self.delta * S)\n",
        "    N = list(X.size())[1]\n",
        "    d = torch.mm(K.t(), torch.ones(N, 1).cuda())\n",
        "    q = 1 / d\n",
        "    D_inv = torch.diagflat(q)\n",
        "    eye = torch.eye(N).cuda()\n",
        "    P = ((1-self.eta) * eye) + (self.eta * torch.mm(K, D_inv))\n",
        "    return torch.mm(X, P)\n",
        "  \n",
        "  def forward(self, X):\n",
        "    \n",
        "    clust_embs = [0] * self.ms_iter\n",
        "  \n",
        "    clust_embs[0] = self.mean_shift_once(X)\n",
        "  \n",
        "    for it in range(1, self.ms_iter):\n",
        "      clust_embs[it] = self.mean_shift_once(clust_embs[it-1])\n",
        "    \n",
        "    return clust_embs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GEc_XG7FbjMy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loss"
      ]
    },
    {
      "metadata": {
        "id": "-EAO6vDtjVTt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### MS Loss"
      ]
    },
    {
      "metadata": {
        "id": "8VM7uD9VbmRN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Loss(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, alpha):\n",
        "    super(Loss, self).__init__()\n",
        "    self.alpha = alpha\n",
        "\n",
        "  def cluster_loss(self, embeddings, y):\n",
        "\n",
        "    num_classes = len(np.unique(y)) \n",
        "    num_samples_for_each_class = [0 for i in range(num_classes)] \n",
        "    for i in y:\n",
        "      num_samples_for_each_class[int(i)] += 1\n",
        "\n",
        "    total = len(y)\n",
        "    loss = 0\n",
        "    cos_sim = torch.nn.CosineSimilarity(dim=0)\n",
        "    \n",
        "    for i in range(total):\n",
        "      for j in range(i+1, total):\n",
        "        w_i = 1 / num_samples_for_each_class[y[i]] \n",
        "        w_j = 1 / num_samples_for_each_class[y[j]]\n",
        "        if y[i] == y[j]:\n",
        "          loss += (w_i * w_j) * (1 - cos_sim(embeddings[i] , embeddings[j])) \n",
        "        else:\n",
        "          loss += (w_i * w_j) * (torch.clamp(cos_sim(embeddings[i] , embeddings[j]) - alpha , 0)) \n",
        "\n",
        "    return loss/y.shape[0]\n",
        "  \n",
        "  def regen_loss(self, X, X_):\n",
        "    \n",
        "    ae_loss = torch.nn.MSELoss()\n",
        "    regen_loss = ae_loss(X, X_)/(X.size()[0]*X.size()[1]*X.size()[2]*X.size()[3])\n",
        "\n",
        "    return regen_loss\n",
        "    \n",
        "  def forward(self, X, X_, embeddings, y):\n",
        "    \n",
        "    ms_loss = self.cluster_loss(embeddings[0].t(), y)/len(embeddings)\n",
        "    \n",
        "    for i in range(1, len(embeddings)):\n",
        "      ms_loss += self.cluster_loss(embeddings[i].t(), y)/len(embeddings)\n",
        "    \n",
        "    ae_loss = self.regen_loss(X, X_)\n",
        "\n",
        "    return ms_loss + ae_loss, ms_loss.cpu().detach().numpy(), ae_loss.cpu().detach().numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JGZZQXtQxq_E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Weigh init"
      ]
    },
    {
      "metadata": {
        "id": "YM0TzTDexuE5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find('Conv') != -1:\n",
        "    nn.init.xavier_uniform_(m.weight.data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PeOIbNvIxpCi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "id": "81qDeWHQeIU_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AE(nn.Module):\n",
        "  def __init__(self, z_len):\n",
        "    super(AE, self).__init__()\n",
        "\n",
        "    self.conv_1 = nn.Conv2d(1, 20, kernel_size=5, stride=1)\n",
        "    self.pool = nn.MaxPool2d(2, 2, return_indices=True)\n",
        "    self.ind1 = 0\n",
        "    self.ind2 = 0\n",
        "    self.conv_2 = nn.Conv2d(20, 50, kernel_size=5, stride=1)\n",
        "    self.fc_1 = nn.Linear(4*4*50, 500)\n",
        "    self.fc_2 = nn.Linear(500,z_len)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "#     self.alpha = alpha\n",
        "#     self.delta = 3 / (1-self.alpha)\n",
        "#     self.eta = eta\n",
        "#     self.ms_iter = ms_iter\n",
        "\n",
        "    self.upfc_1 = nn.Linear(z_len, 500)\n",
        "    self.upfc_2 = nn.Linear(500, 4*4*50)\n",
        "    self.unpool = nn.MaxUnpool2d(2, 2)\n",
        "    self.upconv_1 = nn.ConvTranspose2d(50, 20, kernel_size=5, stride=1)\n",
        "    self.upconv_2 = nn.ConvTranspose2d(20, 1, kernel_size=5, stride=1)  \n",
        "\n",
        "  def encode(self, x):\n",
        "    z = self.conv_1(x)\n",
        "    z = self.relu(z)\n",
        "    z, self.ind1 = self.pool(z)\n",
        "    z = self.conv_2(z)\n",
        "    z = self.relu(z)\n",
        "    z, self.ind2 = self.pool(z)\n",
        "    z = z.view(z.size(0), -1)\n",
        "    z = self.fc_1(z)\n",
        "    z = self.relu(z)\n",
        "    z = self.fc_2(z)\n",
        "    z_norm = z.norm(p=2, dim=1, keepdim=True).detach()\n",
        "    z = z.div(z_norm.expand_as(z))\n",
        "    return z\n",
        "\n",
        "#   def mean_shift_cluster(self, X, delta, eta):\n",
        "#     S = torch.mm(X.t(), X)\n",
        "#     K = torch.exp(delta * S)\n",
        "#     N = list(X.size())[1]\n",
        "#     d = torch.mm(K.t(), torch.ones(N, 1).cuda())\n",
        "#     q = 1 / d\n",
        "#     D_inv = torch.diagflat(q)\n",
        "#     eye = torch.eye(N).cuda()\n",
        "#     P = ((1-eta) * eye) + (eta * torch.mm(K, D_inv))\n",
        "#     return torch.mm(X, P)\n",
        "\n",
        "  def decode(self, z):\n",
        "    x = self.upfc_1(z)\n",
        "    x = self.relu(x)\n",
        "    x = self.upfc_2(x)\n",
        "    x = x.view(x.size(0), 50, 4, 4)\n",
        "    x = self.unpool(x, self.ind2)\n",
        "    x = self.relu(x)\n",
        "    x = self.upconv_1(x)\n",
        "    x = self.unpool(x, self.ind1)\n",
        "    x = self.relu(x)\n",
        "    x = self.upconv_2(x)\n",
        "    x = (x - 0.5) / 1.0\n",
        "    return x\n",
        "\n",
        "  def forward(self, x):\n",
        "    \n",
        "    z = self.encode(x)\n",
        "\n",
        "#     embeds = []\n",
        "#     for i in range(self.ms_iter):\n",
        "#       embeds.append(self.mean_shift_cluster(z.t(), self.delta, self.eta))\n",
        "\n",
        "#     x = self.decode(embeds[-1].t())\n",
        "  \n",
        "    x = self.decode(z)\n",
        "    \n",
        "    return x, z.t()\n",
        "#     return x, embeds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FshaBj1BcbfD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Init"
      ]
    },
    {
      "metadata": {
        "id": "OWNPvpYWo0hw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Params"
      ]
    },
    {
      "metadata": {
        "id": "HU65pr02cfEC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alpha = 0.5 \n",
        "eta = 1 \n",
        "ms_iter = 3\n",
        "delta = 3 / (1-alpha)\n",
        "total_epochs = 60\n",
        "embedding_dim = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uHmsc0U2o6c-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Init"
      ]
    },
    {
      "metadata": {
        "id": "3_XYa_d5o3iY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = AE(embedding_dim)\n",
        "model.apply(weights_init)\n",
        "model = model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "ms_clust = Mean_Shift_Cluster(delta, eta, ms_iter)\n",
        "\n",
        "ms_ae_loss = Loss(alpha)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dBPCDMKsyW2K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train"
      ]
    },
    {
      "metadata": {
        "id": "w79YozqGvqsB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model = AE(embedding_dim)\n",
        "# model.load_state_dict(torch.load('/gdrive/My Drive/mean shift data/ms_ae_final.pt'))\n",
        "# model = model.cuda()\n",
        "\n",
        "epoch_avg_total_loss = [0]*total_epochs\n",
        "\n",
        "epoch_avg_cluster_loss = [0]*total_epochs\n",
        "\n",
        "epoch_avg_regen_loss = [0]*total_epochs\n",
        "\n",
        "# total_loss_win = vis.line(\n",
        "#     Y=np.zeros((1)),\n",
        "#     X=np.zeros((1)),\n",
        "#     opts=dict(xlabel='epoch',title='Total Loss',ylabel='training loss',legend=['Loss']))\n",
        "\n",
        "# cluster_loss_win = vis.line(\n",
        "#     Y=np.zeros((1)),\n",
        "#     X=np.zeros((1)),\n",
        "#     opts=dict(xlabel='epoch',title='Cluster Loss',ylabel='training loss',legend=['Loss']))\n",
        "\n",
        "# regen_loss_win = vis.line(\n",
        "#     Y=np.zeros((1)),\n",
        "#     X=np.zeros((1)),\n",
        "#     opts=dict(xlabel='epoch',title='Regen Loss',ylabel='training loss',legend=['Loss']))\n",
        "\n",
        "for epoch in range(total_epochs):\n",
        "  \n",
        "  print('epoch', epoch)\n",
        "  \n",
        "  avg_total_loss = 0\n",
        "  avg_cluster_loss = 0\n",
        "  avg_regen_loss = 0\n",
        "    \n",
        "  for batch_idx, (x, target) in enumerate(train_loader):\n",
        "\n",
        "    optimizer.zero_grad()        \n",
        "    x, target = x.cuda(), target.numpy()\n",
        "\n",
        "    x_, z = model(x)\n",
        "    \n",
        "    clust_embs = ms_clust(z)\n",
        "    \n",
        "    total_loss, cluster_loss, regen_loss = ms_ae_loss(x, x_, clust_embs, target)\n",
        "    \n",
        "    print('epoch', epoch, 'batch', batch_idx, 'batch total loss', total_loss.cpu().detach().numpy())\n",
        "    print('epoch', epoch, 'batch', batch_idx, 'batch cluster loss', cluster_loss)\n",
        "    print('epoch', epoch, 'batch', batch_idx, 'batch regen loss', regen_loss)\n",
        "    \n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    avg_total_loss += total_loss.cpu().detach().numpy()\n",
        "    avg_cluster_loss += cluster_loss\n",
        "    avg_regen_loss += regen_loss\n",
        "    \n",
        "    if batch_idx % 50 == 0:\n",
        "      print('saving...')\n",
        "      torch.save(model.state_dict(), '/gdrive/My Drive/mean shift data/ms_ae_final.pt')\n",
        "      print()\n",
        "   \n",
        "  epoch_avg_total_loss[epoch] = avg_total_loss/total_epochs\n",
        "  epoch_avg_cluster_loss[epoch] = avg_cluster_loss/total_epochs\n",
        "  epoch_avg_regen_loss[epoch] = avg_regen_loss/total_epochs\n",
        "  \n",
        "  loss_file = open('/gdrive/My Drive/mean shift data/loss_list_final.pkl', 'wb')\n",
        "  pickle.dump([epoch_avg_total_loss, epoch_avg_cluster_loss, epoch_avg_regen_loss], loss_file)\n",
        "  # pickle.dump([epoch_avg_total_loss], loss_file)\n",
        "  loss_file.close()\n",
        "\n",
        "  print('epoch', epoch, 'epoch avg cluster loss', epoch_avg_total_loss[epoch])\n",
        "  print('epoch', epoch, 'epoch avg cluster loss', epoch_avg_cluster_loss[epoch])\n",
        "  print('epoch', epoch, 'epoch avg regen loss', epoch_avg_regen_loss[epoch])\n",
        "  print()\n",
        "#   vis.line(X=np.ones(1)*(epoch+1),Y=np.array([epoch_avg_total_loss[epoch]]),win=total_loss_win,update='append')\n",
        "#   vis.line(X=np.ones(1)*(epoch+1),Y=np.array([epoch_avg_cluster_loss[epoch]]),win=cluster_loss_win,update='append')\n",
        "#   vis.line(X=np.ones(1)*(epoch+1),Y=np.array([epoch_avg_regen_loss[epoch]]),win=regen_loss_win,update='append')\n",
        "  plot_regen(model)\n",
        "  print('saving...')\n",
        "  torch.save(model.state_dict(), '/gdrive/My Drive/mean shift data/ms_ae_final.pt')\n",
        "  print()\n",
        " \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LRQj6YFDwzWS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Scratch Code"
      ]
    },
    {
      "metadata": {
        "id": "iQnIodoBwxbg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = torch.randn((100, 1, 28, 28))\n",
        "\n",
        "model = AE().cuda()\n",
        "\n",
        "X_ = model(X)\n",
        "print(X_.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_xlerWu8mnow",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_regen(model):\n",
        "  im_data = mnist.MNIST('/content/raw/')\n",
        "\n",
        "  train_image, train_label = im_data.load_training()\n",
        "\n",
        "  train_image = np.array(train_image)\n",
        "\n",
        "  train_label = np.array(train_label)\n",
        "\n",
        "  train_image = train_image.reshape(-1, 28, 28, 1)\n",
        "\n",
        "  fig=plt.figure(figsize=(17,70))\n",
        "\n",
        "  # print(train_image[0].shape)\n",
        "  num_im = 4\n",
        "  for i in range(num_im):\n",
        "    data = np.array(train_image[i], dtype='float')\n",
        "    data = data.reshape((28, 28))\n",
        "    fig.add_subplot(1, num_im, i+1)\n",
        "    plt.imshow(data, cmap='gray')\n",
        "  plt.show()\n",
        "\n",
        "  fig=plt.figure(figsize=(17,70))\n",
        "\n",
        "  # print(train_image[0].shape)\n",
        "  num_im = 4\n",
        "  for i in range(num_im):\n",
        "\n",
        "    data = np.array(train_image[i], dtype='float')\n",
        "    data = data.reshape((28, 28, 1))\n",
        "    data = np.transpose(data)\n",
        "    data = data.reshape((1, 1, 28, 28))\n",
        "\n",
        "    data = torch.from_numpy(data)\n",
        "    data = (data.float() - 0.5) / 1.0\n",
        "    out, embed = model(data.cuda())\n",
        "\n",
        "    out = out.cpu().detach()\n",
        "    out = out.reshape((28, 28))\n",
        "    out = np.array(out, dtype='float')\n",
        "    out = (out * 1.0) + 0.5\n",
        "    out = (out - np.min(out)) * 255 / (np.max(out) - np.min(out))\n",
        "    up = np.where(out >= 128)\n",
        "    down = np.where(out < 128)\n",
        "    out[up] = 1.\n",
        "    out[down] = 0.\n",
        "    fig.add_subplot(1, num_im, i+1)\n",
        "    plt.imshow(out.T, cmap='gray')\n",
        "  plt.show()\n",
        "  \n",
        "plot_regen(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0xwRwhdN_7nE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E_3NdxSxEgkC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# torch.save(the_model.state_dict(), '/con')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVRZPhHAu2Hj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/gdrive/My Drive/mean shift data/ms_ae.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XDMfMnzgvXmg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2 = AE()\n",
        "model2.load_state_dict(torch.load('/gdrive/My Drive/mean shift data/ms_ae.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4jBNLUo8xQW_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2 = model2.cuda()\n",
        "data = np.array(train_image[7], dtype='float')\n",
        "data = data.reshape((28, 28, 1))\n",
        "data = np.transpose(data)\n",
        "data = data.reshape((1, 1, 28, 28))\n",
        "\n",
        "data = torch.from_numpy(data)\n",
        "# print(data.size())\n",
        "data = (data.float() - 0.5) / 1.0\n",
        "out, embed = model2(data.cuda())\n",
        "\n",
        "out = out.cpu().detach()\n",
        "out = out.reshape((28, 28))\n",
        "out = np.array(out, dtype='float')\n",
        "# print(out)\n",
        "out = (out * 1.0) + 0.5\n",
        "out = (out - np.min(out)) * 255 / (np.max(out) - np.min(out))\n",
        "plt.imshow(out.T, cmap='gray')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k8SwU1vnUNxY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file = open('/gdrive/My Drive/mean shift data/loss_list_3.pkl', 'rb')\n",
        "temp = pickle.load(file)\n",
        "loss = temp[0]\n",
        "# file = open('/gdrive/My Drive/mean shift data/loss_list_1.pkl', 'rb')\n",
        "# temp = pickle.load(file)\n",
        "# loss = np.concatenate((loss, temp[0]))\n",
        "# file = open('/gdrive/My Drive/mean shift data/loss_list_2.pkl', 'rb')\n",
        "# temp = pickle.load(file)\n",
        "# loss = np.concatenate((loss, temp[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "89b2W1goulLM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(loss)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('autoencoder w/o mean shift')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FALdDVaauo45",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mean_shift_once(X, delta, eta=1):\n",
        "  \n",
        "  K = torch.exp(delta * torch.mm(X.t(), X))\n",
        "  \n",
        "  N = list(X.size())[1]\n",
        "  ones = torch.ones(N, 1).cuda()\n",
        "  D = torch.diagflat(torch.mm(K.t(), ones))\n",
        "  D_inv = D.inverse()\n",
        "  \n",
        "  eye = torch.eye(N).cuda()\n",
        "  \n",
        "  shift = (eta * torch.mm(K, D_inv)) + ((1 - eta) * eye)\n",
        "  X = torch.mm(X, shift)\n",
        "  \n",
        "  return X\n",
        "\n",
        "x = torch.randn((60000, 10)).cuda()\n",
        "out = mean_shift_once(x, 1/(1+0.35))\n",
        "\n",
        "x.size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mvnbztQVV7ru",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cluster_loss(embeddings, y, alpha):\n",
        "        \n",
        "        num_classes = len(np.unique(y)) \n",
        "        num_samples_for_each_class = [0 for i in range(num_classes)] \n",
        "        for i in y:\n",
        "            num_samples_for_each_class[int(i)] += 1\n",
        "        \n",
        "        total = len(y)\n",
        "        loss = 0\n",
        "        cos_sim = torch.nn.CosineSimilarity(dim=0)\n",
        "        for i in range(total):\n",
        "            for j in range(i+1, total):\n",
        "                w_i = 1 / num_samples_for_each_class[y[i]] \n",
        "                w_j = 1 / num_samples_for_each_class[y[j]]\n",
        "                if y[i] == y[j]:\n",
        "                    loss += (w_i * w_j) * (1 - cos_sim(embeddings[i] , embeddings[j])) \n",
        "                else:\n",
        "                    loss += (w_i * w_j) * (torch.clamp(cos_sim(embeddings[i] , embeddings[j]) - alpha , 0)) \n",
        "\n",
        "        return loss/(y.shape[0]*10)\n",
        "\n",
        "model3 = AE()\n",
        "\n",
        "model3 = model3.cuda()\n",
        "\n",
        "for batch_idx, (x, target) in enumerate(train_loader):\n",
        "\n",
        "  total_loss = 0\n",
        "\n",
        "  x, target = x.cuda(), target.detach()\n",
        "  \n",
        "  out = model3.encode(x)\n",
        "  \n",
        "  cluster = mean_shift_once(out, 1/(1+0.35))\n",
        "  \n",
        "  loss = cluster_loss(cluster, target, 0.5)\n",
        "  \n",
        "  print(loss)\n",
        "  \n",
        "  break\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BUkCJNHaYgG8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !/usr/local/bin/python -m pip install visdom\n",
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# !unzip ngrok-stable-linux-amd64.zip\n",
        "port = 6006\n",
        "get_ipython().system_raw('/usr/local/bin/python -m visdom.server -port ' + str(port) + ' >> visdomlog.txt 2>&1 &')\n",
        "get_ipython().system_raw('lt --port ' + str(port) + '>> url.txt 2>&1 &')\n",
        "\n",
        "get_ipython().system_raw('./ngrok http ' + str(port) + ' &')\n",
        "print('curl')\n",
        "! curl -s http://localhost:4040/api/tunnels | python -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NRbz8vEt6-_y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print(vis)\n",
        "vis.text('testing')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOa-wGqN7SyK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}